{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMUj1syTz38G"
      },
      "source": [
        " #inputs- document term matrix - bow - term and its count\n",
        " #input2- number of topics \n",
        " #number of iteration"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SDUmhO91vPt"
      },
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import glob\n",
        "\n",
        "#Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "#spacy\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "#vis\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EZltL27D1oa"
      },
      "source": [
        "def load_data(file):\n",
        "    with open (file, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f) \n",
        "    return (data)\n",
        "\n",
        "def write_data(file, data):\n",
        "    with open (file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, indent=4)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJGbwsBLEQBR"
      },
      "source": [
        "stopwords = stopwords.words(\"english\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuBxSltdESjo"
      },
      "source": [
        "data = load_data(\"data/ushmm_dn.json\")[\"texts\"]\n",
        "\n",
        "print (data[0][0:90])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCk7RJZpEWIw"
      },
      "source": [
        "def lemmatization(texts, allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]):\n",
        "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
        "    texts_out = []\n",
        "    for text in texts:\n",
        "        doc = nlp(text)\n",
        "        new_text = []\n",
        "        for token in doc:\n",
        "            if token.pos_ in allowed_postags:\n",
        "                new_text.append(token.lemma_)\n",
        "        final = \" \".join(new_text)\n",
        "        texts_out.append(final)\n",
        "    return (texts_out)\n",
        "\n",
        "\n",
        "lemmatized_texts = lemmatization(data)\n",
        "print (lemmatized_texts[0][0:90])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMP6d8W2EbC3"
      },
      "source": [
        "def gen_words(texts):\n",
        "    final = []\n",
        "    for text in texts:\n",
        "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
        "        final.append(new)\n",
        "    return (final)\n",
        "\n",
        "data_words = gen_words(lemmatized_texts)\n",
        "\n",
        "print (data_words[0][0:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzXC30_KEgo5"
      },
      "source": [
        "id2word = corpora.Dictionary(data_words)\n",
        "\n",
        "corpus = []\n",
        "for text in data_words:\n",
        "    new = id2word.doc2bow(text)\n",
        "    corpus.append(new)\n",
        "\n",
        "print (corpus[0][0:20])\n",
        "\n",
        "word = id2word[[0][:1][0]]\n",
        "print (word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-jlOA8nEin_"
      },
      "source": [
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=30,\n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha=\"auto\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBRo3Rb-ElWP"
      },
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds=\"mmds\", R=30)\n",
        "vis"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}